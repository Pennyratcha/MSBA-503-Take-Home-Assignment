{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d0314fa-1bf9-4f58-9be3-e8410a570ae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\penny\\anaconda3\\lib\\site-packages (2.5.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\penny\\anaconda3\\lib\\site-packages (0.20.1)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\penny\\anaconda3\\lib\\site-packages (4.10.0.84)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\penny\\anaconda3\\lib\\site-packages (3.8.4)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\penny\\anaconda3\\lib\\site-packages (2.18.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement detectron2 (from versions: none)\n",
      "ERROR: No matching distribution found for detectron2\n"
     ]
    }
   ],
   "source": [
    "pip install torch torchvision opencv-python matplotlib tensorflow detectron2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dfe39856-f5a3-4f61-a9e6-14f242f4bc7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ultralytics in c:\\users\\penny\\anaconda3\\lib\\site-packages (8.3.40)\n",
      "Requirement already satisfied: numpy>=1.23.0 in c:\\users\\penny\\anaconda3\\lib\\site-packages (from ultralytics) (1.26.4)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in c:\\users\\penny\\anaconda3\\lib\\site-packages (from ultralytics) (3.8.4)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in c:\\users\\penny\\anaconda3\\lib\\site-packages (from ultralytics) (4.10.0.84)\n",
      "Requirement already satisfied: pillow>=7.1.2 in c:\\users\\penny\\anaconda3\\lib\\site-packages (from ultralytics) (10.3.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in c:\\users\\penny\\anaconda3\\lib\\site-packages (from ultralytics) (6.0.1)\n",
      "Requirement already satisfied: requests>=2.23.0 in c:\\users\\penny\\anaconda3\\lib\\site-packages (from ultralytics) (2.32.2)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\penny\\anaconda3\\lib\\site-packages (from ultralytics) (1.13.1)\n",
      "Requirement already satisfied: torch>=1.8.0 in c:\\users\\penny\\anaconda3\\lib\\site-packages (from ultralytics) (2.5.1)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in c:\\users\\penny\\anaconda3\\lib\\site-packages (from ultralytics) (0.20.1)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in c:\\users\\penny\\anaconda3\\lib\\site-packages (from ultralytics) (4.66.4)\n",
      "Requirement already satisfied: psutil in c:\\users\\penny\\anaconda3\\lib\\site-packages (from ultralytics) (5.9.0)\n",
      "Requirement already satisfied: py-cpuinfo in c:\\users\\penny\\anaconda3\\lib\\site-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in c:\\users\\penny\\anaconda3\\lib\\site-packages (from ultralytics) (2.2.2)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in c:\\users\\penny\\anaconda3\\lib\\site-packages (from ultralytics) (0.13.2)\n",
      "Requirement already satisfied: ultralytics-thop>=2.0.0 in c:\\users\\penny\\anaconda3\\lib\\site-packages (from ultralytics) (2.0.12)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\penny\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\penny\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\penny\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\penny\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\penny\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (23.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\penny\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\penny\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\penny\\anaconda3\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\penny\\anaconda3\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\penny\\anaconda3\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\penny\\anaconda3\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\penny\\anaconda3\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\penny\\anaconda3\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2024.7.4)\n",
      "Requirement already satisfied: filelock in c:\\users\\penny\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\penny\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (4.11.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\penny\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\penny\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\penny\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (2024.3.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\penny\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (69.5.1)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\penny\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\penny\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\penny\\anaconda3\\lib\\site-packages (from tqdm>=4.64.0->ultralytics) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\penny\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\penny\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install ultralytics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e36afa11-5c86-449a-9eb8-0a919f6f1a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "def yolo_object_detection(image_path):\n",
    "    model = YOLO('yolov5s.pt')  \n",
    "\n",
    "    results = model(image_path)\n",
    "\n",
    "    detected_objects = []\n",
    "    for box in results[0].boxes:\n",
    "        detected_objects.append({\n",
    "            \"class\": box.cls.cpu().numpy().item(), \n",
    "            \"confidence\": box.conf.cpu().numpy().item()  \n",
    "        })\n",
    "\n",
    "    detection_time = results[0].speed[\"inference\"] / 1000  \n",
    "\n",
    "    return detected_objects, detection_time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d241a64-5d76-4961-9701-996ad8a7d667",
   "metadata": {},
   "source": [
    "Part A (i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd06a44a-d715-4e96-9c06-c44a06472355",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as T\n",
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
    "\n",
    "def faster_rcnn_object_detection(image_path):\n",
    "    model = fasterrcnn_resnet50_fpn(weights=\"DEFAULT\")  \n",
    "    model.eval()  \n",
    "\n",
    "    image = cv2.imread(image_path)\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    transform = T.ToTensor()  \n",
    "    image_tensor = transform(image_rgb).unsqueeze(0)  \n",
    "\n",
    "    start_time = time.time()\n",
    "    predictions = model(image_tensor)  \n",
    "    end_time = time.time()\n",
    "\n",
    "    detected_objects = []\n",
    "    for i in range(len(predictions[0]['boxes'])):\n",
    "        if predictions[0]['scores'][i] > 0.5:  #\n",
    "            detected_objects.append({\n",
    "                \"box\": predictions[0]['boxes'][i].detach().numpy().tolist(),\n",
    "                \"label\": predictions[0]['labels'][i].item(),\n",
    "                \"score\": predictions[0]['scores'][i].item()\n",
    "            })\n",
    "\n",
    "    detection_time = end_time - start_time\n",
    "    return detected_objects, detection_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "96bd591a-b9e4-49a7-8228-fd6f85a59693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRO TIP  Replace 'model=yolov5s.pt' with new 'model=yolov5su.pt'.\n",
      "YOLOv5 'u' models are trained with https://github.com/ultralytics/ultralytics and feature improved performance vs standard YOLOv5 models trained with https://github.com/ultralytics/yolov5.\n",
      "\n",
      "\n",
      "image 1/1 C:\\Users\\Penny\\image1.jpg: 448x640 2 birds, 158.2ms\n",
      "Speed: 1.0ms preprocess, 158.2ms inference, 0.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "PRO TIP  Replace 'model=yolov5s.pt' with new 'model=yolov5su.pt'.\n",
      "YOLOv5 'u' models are trained with https://github.com/ultralytics/ultralytics and feature improved performance vs standard YOLOv5 models trained with https://github.com/ultralytics/yolov5.\n",
      "\n",
      "\n",
      "image 1/1 C:\\Users\\Penny\\image2.jpg: 448x640 1 cup, 1 cell phone, 2 books, 110.6ms\n",
      "Speed: 1.9ms preprocess, 110.6ms inference, 0.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "PRO TIP  Replace 'model=yolov5s.pt' with new 'model=yolov5su.pt'.\n",
      "YOLOv5 'u' models are trained with https://github.com/ultralytics/ultralytics and feature improved performance vs standard YOLOv5 models trained with https://github.com/ultralytics/yolov5.\n",
      "\n",
      "\n",
      "image 1/1 C:\\Users\\Penny\\image3.jpg: 544x640 2 persons, 2 sports balls, 170.3ms\n",
      "Speed: 2.9ms preprocess, 170.3ms inference, 0.0ms postprocess per image at shape (1, 3, 544, 640)\n",
      "PRO TIP  Replace 'model=yolov5s.pt' with new 'model=yolov5su.pt'.\n",
      "YOLOv5 'u' models are trained with https://github.com/ultralytics/ultralytics and feature improved performance vs standard YOLOv5 models trained with https://github.com/ultralytics/yolov5.\n",
      "\n",
      "\n",
      "image 1/1 C:\\Users\\Penny\\image4.jpg: 448x640 1 tv, 113.0ms\n",
      "Speed: 1.5ms preprocess, 113.0ms inference, 0.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "PRO TIP  Replace 'model=yolov5s.pt' with new 'model=yolov5su.pt'.\n",
      "YOLOv5 'u' models are trained with https://github.com/ultralytics/ultralytics and feature improved performance vs standard YOLOv5 models trained with https://github.com/ultralytics/yolov5.\n",
      "\n",
      "\n",
      "image 1/1 C:\\Users\\Penny\\image5.jpg: 480x640 3 chairs, 127.7ms\n",
      "Speed: 1.0ms preprocess, 127.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "        Image  YOLO Objects  YOLO Time (s)  Faster R-CNN Objects  \\\n",
      "0  image1.jpg             2       0.158152                     1   \n",
      "1  image2.jpg             4       0.110585                     9   \n",
      "2  image3.jpg             4       0.170335                     4   \n",
      "3  image4.jpg             1       0.112956                     4   \n",
      "4  image5.jpg             3       0.127696                     9   \n",
      "\n",
      "   Faster R-CNN Time (s)  \n",
      "0               1.664712  \n",
      "1               1.812152  \n",
      "2               1.499114  \n",
      "3               1.729123  \n",
      "4               1.704539  \n"
     ]
    }
   ],
   "source": [
    "import cv2  \n",
    "import pandas as pd\n",
    "import torchvision.transforms as T\n",
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
    "from ultralytics import YOLO\n",
    "import time\n",
    "\n",
    "image_paths = [\"image1.jpg\", \"image2.jpg\", \"image3.jpg\", \"image4.jpg\", \"image5.jpg\"]  \n",
    "results = []\n",
    "\n",
    "for img in image_paths:\n",
    "    yolo_result, yolo_time = yolo_object_detection(img)\n",
    "    \n",
    "    rcnn_result, rcnn_time = faster_rcnn_object_detection(img)\n",
    "    \n",
    "    results.append({\n",
    "        \"Image\": img,\n",
    "        \"YOLO Objects\": len(yolo_result),\n",
    "        \"YOLO Time (s)\": yolo_time,\n",
    "        \"Faster R-CNN Objects\": len(rcnn_result),\n",
    "        \"Faster R-CNN Time (s)\": rcnn_time\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "print(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442a2534-0655-476f-ae3e-d7587bed892b",
   "metadata": {},
   "source": [
    "Part 1 (ii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a6e1cadd-a2bd-4fce-828d-8a6e495110c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dominant Color for image1.jpg: [     78.797      100.97      91.074]\n",
      "Dominant Color for image2.jpg: [      195.3      195.77      195.32]\n",
      "Dominant Color for image3.jpg: [     55.814      103.27      83.588]\n",
      "Dominant Color for image4.jpg: [     116.39      112.11      106.34]\n",
      "Dominant Color for image5.jpg: [     102.94      118.21      134.99]\n"
     ]
    }
   ],
   "source": [
    "#Extract Colors\n",
    "def extract_features(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    dominant_color = image.mean(axis=(0, 1))  \n",
    "    return dominant_color\n",
    "\n",
    "for img in image_paths:\n",
    "    features = extract_features(img)\n",
    "    print(f\"Dominant Color for {img}: {features}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9fbeb320-45c7-402d-9a5b-564bc89ecee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of edges in image1.jpg: 14737\n",
      "Number of edges in image2.jpg: 17127\n",
      "Number of edges in image3.jpg: 24484\n",
      "Number of edges in image4.jpg: 12817\n",
      "Number of edges in image5.jpg: 64509\n"
     ]
    }
   ],
   "source": [
    "#Count Edges\n",
    "import numpy as np\n",
    "\n",
    "def extract_edge_count(image_path):\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    edges = cv2.Canny(image, 100, 200)  \n",
    "    edge_count = np.sum(edges > 0)  \n",
    "    return edge_count\n",
    "\n",
    "for img in image_paths:\n",
    "    edges = extract_edge_count(img)\n",
    "    print(f\"Number of edges in {img}: {edges}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "43818d36-a196-4076-a937-e78c4064e71e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image1.jpg: Height = 435, Width = 640, Aspect Ratio = 1.47\n",
      "image2.jpg: Height = 426, Width = 640, Aspect Ratio = 1.50\n",
      "image3.jpg: Height = 514, Width = 640, Aspect Ratio = 1.25\n",
      "image4.jpg: Height = 427, Width = 640, Aspect Ratio = 1.50\n",
      "image5.jpg: Height = 480, Width = 640, Aspect Ratio = 1.33\n"
     ]
    }
   ],
   "source": [
    "#Extract Image Dimensions\n",
    "def extract_image_dimensions(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    height, width = image.shape[:2]\n",
    "    aspect_ratio = width / height\n",
    "    return height, width, aspect_ratio\n",
    "\n",
    "for img in image_paths:\n",
    "    height, width, ratio = extract_image_dimensions(img)\n",
    "    print(f\"{img}: Height = {height}, Width = {width}, Aspect Ratio = {ratio:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2ec34603-7176-44c8-b2c3-e9173aeadb45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brightness of image1.jpg: 95.48\n",
      "Brightness of image2.jpg: 195.56\n",
      "Brightness of image3.jpg: 91.92\n",
      "Brightness of image4.jpg: 110.84\n",
      "Brightness of image5.jpg: 121.51\n"
     ]
    }
   ],
   "source": [
    "#Brightness or Contrast\n",
    "def calculate_brightness(image_path):\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    brightness = np.mean(image)  \n",
    "    return brightness\n",
    "\n",
    "for img in image_paths:\n",
    "    brightness = calculate_brightness(img)\n",
    "    print(f\"Brightness of {img}: {brightness:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7189bdf2-5a96-417a-900a-b694f8aae5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Acknowldegemnt: images from koustubhk on Kaggle"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
